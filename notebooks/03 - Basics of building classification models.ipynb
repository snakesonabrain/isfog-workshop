{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics of building classification models\n",
    "\n",
    "Classification models are used to define a model which predicts a discrete variable from a number of observations. Classification modelling might be less common in (geotechnical) engineering but there are still a number of useful applications. For example, soil type classification from CPT records is a classification problem and it will be studied in this notebook.\n",
    "\n",
    "The scikit-learn machine learning library includes several model types to define relations between the observations (features) and the outcome (target).\n",
    "\n",
    "In this notebook, we will show how a simple classification model can be created, how it is trained and how the model accuracy is assessed. The demo is created using data from the Borssele wind farm area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from plotly import subplots\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will import the tree module from scikit-learn to build decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset loading\n",
    "\n",
    "We can load the data from a .csv file. The data has been preprocessed to link soil type class according to Robertson (2010) to cone resistance properties. The soil type class was determined from sampling boreholes adacent to CPT tests. To allow comparison with the Robertson soil type classification charts, the features $ \\log (Q_t) $ and $ \\log (F_r) $ have already been calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data/cleaneddata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data contains some $ \\infty $ values which can be replaced with NaN values using the ``replace`` method on the dataframe. The Nan values can then be dropped from the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robertson's chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphical comparison\n",
    "\n",
    "The features for the Robertson soil type classification chart can be selected and the data can be visualised. It always good to include the verbose explaination of the class numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robertson_dict = {\n",
    "    '1': '1 - Sensitive, fine-grained',\n",
    "    '2': '2 - Organic soils - Peats',\n",
    "    '3': '3 - Clays, clay to silty clay',\n",
    "    '4': '4 - Silt mixtures, clayey silt to silty clay',\n",
    "    '5': '5 - Sand mixtures, silty sand to sand silty',\n",
    "    '6': '6 - Sands, clean sands to silty sands',\n",
    "    '7': '7 - Gravelly sand to sand',\n",
    "    '8': '8 - Very stiff sand to clayey sand',\n",
    "    '9': '9 - Very stiff fine grained'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = subplots.make_subplots(rows=2, cols=3, print_grid=False, subplot_titles=(\n",
    "    '3 - Clays, clay to silty clay', '4 - Silt mixtures, clayey silt to silty clay',\n",
    "    '5 - Sand mixtures, silty sand to sand silty', '6 - Sands, clean sands to silty sands',\n",
    "    '7 - Gravelly sand to sand', '8 - Very stiff sand to clayey sand'))\n",
    "\n",
    "soiltypeclass = 3\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        trace1 = go.Scatter(\n",
    "            x=data[data['Soil type'] == soiltypeclass]['log(Fr)'],\n",
    "            y=data[data['Soil type'] == soiltypeclass]['log(Qt)'],\n",
    "            showlegend=False, mode='markers')\n",
    "        fig.append_trace(trace1, i+1, j+1)\n",
    "        soiltypeclass += 1\n",
    "\n",
    "fig['layout'].update(title='Borssele classification data', height=900, width=1000)  \n",
    "image_list = []\n",
    "for i in range(6):\n",
    "    fig['layout']['xaxis%i' % (i+1)].update(\n",
    "        title='Fr [%]', range=(-1, 1), tickvals=[-1, 0, 1], ticktext=['0.1', '1', '10'])\n",
    "    fig['layout']['yaxis%i' % (i+1)].update(\n",
    "        title='Qt [-]', range=(0, 3), tickvals=[0, 1, 2, 3], ticktext=['1', '10', '100', '1000'])\n",
    "    image_list.append(\n",
    "        dict(source='Images/RobertsonFr.png',\n",
    "             xref='x%i' % (i+1),\n",
    "             yref='y%i' % (i+1),\n",
    "             x=-1, y=3,\n",
    "             sizex=2, sizey=3,\n",
    "             sizing='stretch', opacity=1,\n",
    "             layer='below',\n",
    "        ))\n",
    "fig['layout'].update(images=image_list)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The comparison with Robertson's chart shows that cohesive soils, silts and clean sands are well reasonable well captured. For silty sand and clayey sand, there are a lot of erroneous predictions.\n",
    "\n",
    "### Confusion matrix\n",
    "\n",
    "The Robertson chart is effectively a model, based on two features; $ \\log (Q_t) $ and $ \\log (F_r) $. We can evaluate this model. The column ``Soil type Robertson`` contains the calculated soil type according to Robertson's chart. This allows the creation of a <i>confusion matrix</i> which  contains the predicted label on the X-axis and the true label on the Y-axis.\n",
    "\n",
    "The confusion matrix is a very useful instrument for evaluating the effectiveness of a model. The diagonal of the matrix should be as bright as possible, meaning that model has a high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_robertson = confusion_matrix(\n",
    "    data['Soil type'], data['Soil type Robertson'], labels=[3, 4, 5, 6, 7, 8], normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = subplots.make_subplots(rows=1, cols=1, print_grid=False)\n",
    "\n",
    "_data = go.Heatmap(\n",
    "    z=cf_robertson, x=[3, 4, 5, 6, 7, 8], y=[3, 4, 5, 6, 7, 8], showlegend=False, showscale=True)\n",
    "fig.append_trace(_data, 1, 1)\n",
    "fig['layout']['xaxis1'].update(title='Predicted class', tickvals=[3, 4, 5, 6, 7, 8])\n",
    "fig['layout']['yaxis1'].update(title='True class', tickvals=[3, 4, 5, 6, 7, 8])\n",
    "fig['layout'].update(title='Confusion matrix for Robertson chart', height=600, width=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuray score\n",
    "\n",
    "The accuracy score can also be calculated as follows:\n",
    "\n",
    "$$ \\text{Accuracy} = \\frac{\\text{No of correct predictions}}{\\text{Total no of predictions}} $$\n",
    "\n",
    "The ``accuracy_score`` function is directly available from scikit-learn and does not need to be coded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_true=data['Soil type'], y_pred=data['Soil type Robertson'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is 39% accurate. Not great, we will see if we can improve this using tree-based classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a decision tree classifier\n",
    "\n",
    "Creating a decision tree classifier is straightforward using ```scikit-learn```. A decision tree is a kind of flow chart in which consecutive questions are answered based on the features of a sample. An example is shown of a decision tree with a depth of 3 (number of questions answered) based on the features $ \\log (Q_t) $ and $ \\log (F_r) $.\n",
    "\n",
    "<img src=\"Images/decision_tree_example.png\">\n",
    "<br><center><b>Decision tree example</b></center>\n",
    "\n",
    "During the model training, the questions which are asked at the nodes are optimised to ensure maximum information gain with each split.\n",
    "\n",
    "It is clear from the decision tree concept that the depth of the tree can be increased until a fully accurate prediction is obtained. This is undesirable since the data itself has uncertainty. The model should therefore not overfit the data. We can solve this through cross-validation whereby the trained model is tested on a batch of unseen data. scikit-learn includes the function ``train_test_split`` which can split the available data intoa train and test set.\n",
    "\n",
    "### Feature selection\n",
    "\n",
    "We can first select features for the model. For this example, we will select $ \\log (Q_t) $ and $ \\log (F_r) $, the same features as in Robertson's chart. The target is the Soil type inferred from the borehole logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['log(Fr)', 'log(Qt)']]\n",
    "y = data['Soil type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test splitting\n",
    "\n",
    "We can split the data keeping 20% as the test set. ``X_train`` and ``y_train`` are the features and target (true value) of the training set and are used to train the classifier. ``X_test`` and ``y_test`` are the features and target of the test set. These are used to evaluate whether the model generalises well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter selection\n",
    "\n",
    "The ``DecisionTreeClassifier`` has several hyperparameters; model parameters which can be modified by the user to control how the tree is built. Documentation on these hyperparameters is provided in the scikit-learn documentation (https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) and any aspiring data scientist should get comfortable with reading function documentation. Documentation provides essential insights in the possiblities of software written by others and ensures that the code created on the basis of this software reaches maximum effectiveness. In data science, a proper choice of hyperparameters can greatly influence model accuracy and generalisation.\n",
    "\n",
    "In this tutorial, we will focus on the hyperparameter ``max_depth`` which controls the maximum number of splits in the tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree models\n",
    "\n",
    "### Maximum depth of 4\n",
    "\n",
    "First, we can create a tree with 4 levels y setting the hyperparameter ``max_depth=4``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_4 = tree.DecisionTreeClassifier(max_depth=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can train this classifier using the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the relatively modest volume of data, the training process is quick. The trained model can now be used to make predictions.\n",
    "\n",
    "First, we can predict the labels for the training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = clf_4.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy score can be assessed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_true=y_train, y_pred=y_pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With an accuracy of 60%, the model is already outperforming Roberton's chart. However, we need to check whether the model also performs well on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = clf_4.predict(X_test)\n",
    "accuracy_score(y_true=y_test, y_pred=y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy on the test is also 60% which indicates that the model generalises well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrices for the train and test set can be visualised:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_4_train = confusion_matrix(\n",
    "    y_train, y_pred_train, labels=[3, 4, 5, 6, 7, 8], normalize='true')\n",
    "cf_4_test = confusion_matrix(\n",
    "    y_test, y_pred_test, labels=[3, 4, 5, 6, 7, 8], normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = subplots.make_subplots(rows=1, cols=2, print_grid=False, subplot_titles=('Training data', 'Test data'))\n",
    "\n",
    "cf_train_trace = go.Heatmap(\n",
    "    z=cf_4_train, x=[3, 4, 5, 6, 7, 8], y=[3, 4, 5, 6, 7, 8], showlegend=False, showscale=True)\n",
    "fig.append_trace(cf_train_trace, 1, 1)\n",
    "cf_test_trace = go.Heatmap(\n",
    "    z=cf_4_test, x=[3, 4, 5, 6, 7, 8], y=[3, 4, 5, 6, 7, 8], showlegend=False, showscale=False)\n",
    "fig.append_trace(cf_test_trace, 1, 2)\n",
    "fig['layout']['xaxis1'].update(title='Predicted class', tickvals=[3, 4, 5, 6, 7, 8])\n",
    "fig['layout']['yaxis1'].update(title='True class', tickvals=[3, 4, 5, 6, 7, 8])\n",
    "fig['layout']['xaxis2'].update(title='Predicted class', tickvals=[3, 4, 5, 6, 7, 8])\n",
    "fig['layout']['yaxis2'].update(title='True class', tickvals=[3, 4, 5, 6, 7, 8])\n",
    "\n",
    "fig['layout'].update(title='Confusion matrix for decision tree with max_depth=4', height=600, width=1000)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that accuracy score alone is insufficient to make judgements on the model quality. For example, clean sands, which were well captured by Robertson's chart are now mostly prediced to be sand mixtures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For further insight in the model behaviour. The decision boundaries for this classifier can be plotted. This is possible since there are only two features. Note that the code shown hereunder is beyond the scope of beginners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fr_min, Fr_max = -1, 1\n",
    "Qt_min, Qt_max = 0, 3\n",
    "\n",
    "h = 0.005\n",
    "\n",
    "Fr, Qt = np.meshgrid(np.arange(Fr_min, Fr_max, h),\n",
    "                     np.arange(Qt_min, Qt_max, h))\n",
    "Z_s = clf_4.predict(np.c_[Fr.ravel(), Qt.ravel()]).reshape(Fr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = subplots.make_subplots(rows=1, cols=1, print_grid=False)\n",
    "_data = go.Heatmap(\n",
    "    z=Z_s, x=np.arange(Fr_min, Fr_max, h), y=np.arange(Qt_min, Qt_max, h), showlegend=False, opacity=0.8)\n",
    "fig.append_trace(_data, 1, 1)\n",
    "for i, _soiltype in enumerate(data['Soil type'].unique()):\n",
    "    _soiltypedata = data[data['Soil type'] == _soiltype]\n",
    "    try:\n",
    "        _name = robertson_dict[\"%.0f\" % _soiltype]\n",
    "    except:\n",
    "        _name = None \n",
    "    _data = go.Scattergl(\n",
    "        y=_soiltypedata['log(Qt)'], x=_soiltypedata['log(Fr)'],\n",
    "        showlegend=True, mode='markers', name=_name,\n",
    "        marker=dict(size=8), opacity=1)\n",
    "    fig.append_trace(_data, 1, 1)\n",
    "fig['layout']['xaxis1'].update(title=r'$ \\log (F_r) \\ \\text{[%]} $', range=(Fr_min, Fr_max))\n",
    "fig['layout']['yaxis1'].update(title=r'$ \\log (Q_t) $', range=(Qt_min, Qt_max))\n",
    "fig['layout'].update(\n",
    "    height=600, width=500,\n",
    "    title='Decision boundaries for decision tree with max depth of 4',\n",
    "    legend=dict(orientation='h', x=0.2, y=-0.2),\n",
    "    images=[\n",
    "        dict(\n",
    "            source='Images/RobertsonFr.png',\n",
    "            xref='x1', yref='y1',\n",
    "            x=Fr_min, y=Qt_max,\n",
    "            sizex=Fr_max - Fr_min, sizey=Qt_max - Qt_min,\n",
    "            sizing='stretch', opacity=1, layer='below',\n",
    "        )],\n",
    "    )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maxium depth of 20\n",
    "\n",
    "To demonstrate how overfitting can obscure data scientists' work, we can create a tree with a large depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_20 = tree.DecisionTreeClassifier(max_depth=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training happens in exactly the same way as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_20.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions can be made and accuracy scores calculated for the test and train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train_20 = clf_20.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_true=y_train, y_pred=y_pred_train_20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy on the training set is very high. This is obviously because the higher maximum depth allows more refinement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_20 = clf_20.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_true=y_test, y_pred=y_pred_test_20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy score on the test set is much poorer, this shows that the model with ``max_depth=20`` overfits the training data and does not generalise well. The training data has too much influence on the data.\n",
    "\n",
    "This can also be observed in the confusion matrices. The confusion matrix for the training data looks very good but the one for the test set is not in line with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_20_train = confusion_matrix(\n",
    "    y_train, y_pred_train_20, labels=[3, 4, 5, 6, 7, 8], normalize='true')\n",
    "cf_20_test = confusion_matrix(\n",
    "    y_test, y_pred_test_20, labels=[3, 4, 5, 6, 7, 8], normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = subplots.make_subplots(rows=1, cols=2, print_grid=False, subplot_titles=('Training data', 'Test data'))\n",
    "\n",
    "cf_train_trace = go.Heatmap(\n",
    "    z=cf_20_train, x=[3, 4, 5, 6, 7, 8], y=[3, 4, 5, 6, 7, 8], showlegend=False, showscale=True)\n",
    "fig.append_trace(cf_train_trace, 1, 1)\n",
    "cf_test_trace = go.Heatmap(\n",
    "    z=cf_20_test, x=[3, 4, 5, 6, 7, 8], y=[3, 4, 5, 6, 7, 8], showlegend=False, showscale=False)\n",
    "fig.append_trace(cf_test_trace, 1, 2)\n",
    "fig['layout']['xaxis1'].update(title='Predicted class', tickvals=[3, 4, 5, 6, 7, 8])\n",
    "fig['layout']['yaxis1'].update(title='True class', tickvals=[3, 4, 5, 6, 7, 8])\n",
    "fig['layout']['xaxis2'].update(title='Predicted class', tickvals=[3, 4, 5, 6, 7, 8])\n",
    "fig['layout']['yaxis2'].update(title='True class', tickvals=[3, 4, 5, 6, 7, 8])\n",
    "\n",
    "fig['layout'].update(title='Confusion matrix for decision tree with max_depth=20', height=600, width=1000)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the boundaries in the parameter space even shows this more clearly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_s_20 = clf_20.predict(np.c_[Fr.ravel(), Qt.ravel()]).reshape(Fr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = subplots.make_subplots(rows=1, cols=1, print_grid=False)\n",
    "_data = go.Heatmap(\n",
    "    z=Z_s_20, x=np.arange(Fr_min, Fr_max, h), y=np.arange(Qt_min, Qt_max, h), showlegend=False, opacity=0.8)\n",
    "fig.append_trace(_data, 1, 1)\n",
    "for i, _soiltype in enumerate(data['Soil type'].unique()):\n",
    "    _soiltypedata = data[data['Soil type'] == _soiltype]\n",
    "    try:\n",
    "        _name = robertson_dict[\"%.0f\" % _soiltype]\n",
    "    except:\n",
    "        _name = None \n",
    "    _data = go.Scattergl(\n",
    "        y=_soiltypedata['log(Qt)'], x=_soiltypedata['log(Fr)'],\n",
    "        showlegend=True, mode='markers', name=_name,\n",
    "        marker=dict(size=8), opacity=1)\n",
    "    fig.append_trace(_data, 1, 1)\n",
    "fig['layout']['xaxis1'].update(title=r'$ \\log (F_r) \\ \\text{[%]} $', range=(Fr_min, Fr_max))\n",
    "fig['layout']['yaxis1'].update(title=r'$ \\log (Q_t) $', range=(Qt_min, Qt_max))\n",
    "fig['layout'].update(\n",
    "    height=600, width=500,\n",
    "    title='Decision boundaries for decision tree with max depth of 20',\n",
    "    legend=dict(orientation='h', x=0.2, y=-0.2),\n",
    "    images=[\n",
    "        dict(\n",
    "            source='Images/RobertsonFr.png',\n",
    "            xref='x1', yref='y1',\n",
    "            x=Fr_min, y=Qt_max,\n",
    "            sizex=Fr_max - Fr_min, sizey=Qt_max - Qt_min,\n",
    "            sizing='stretch', opacity=1, layer='below',\n",
    "        )],\n",
    "    )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The boundaries in the parameter space show very rapid changes from one class to the next. This is not meaningful and is a clear sign of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice\n",
    "\n",
    "In the exercise on classifiers, we will build up a model with multiple features using random forests, an ensemble model which builds up several trees and averages the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
