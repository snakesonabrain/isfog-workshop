{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice - Classification models for soil type determiniation - Assignment\n",
    "\n",
    "In this notebook, we will expand on the tutorial on classification models by building up a model with multiple features using random forests, an ensemble model which builds up several trees and averages the predictions. We will see if the predictions with the simple decision tree from the tutorial can be improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from plotly import subplots\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will import the ``RandomForestClassifier`` class from scikit-learn ``ensemble`` module to build the random forest regressor.\n",
    "\n",
    "For more info on the principle of random forests, you can check the scikit-learn documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ____\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset loading\n",
    "\n",
    "We can load the data from a .csv file. The data has been preprocessed to link soil type class according to Robertson (2010) to cone resistance properties. The soil type class was determined from sampling boreholes adacent to CPT tests. To allow comparison with the Robertson soil type classification charts, the features $ \\log (Q_t) $ and $ \\log (F_r) $ have already been calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.___('Data/___.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data contains some $ \\infty $ values which can be replaced with NaN values using the ``replace`` method on the dataframe. The Nan values can then be dropped from the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create the dictionary with the full names of the soil types according to Robertson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robertson_dict = {\n",
    "    '1': '1 - Sensitive, fine-grained',\n",
    "    '2': '2 - Organic soils - Peats',\n",
    "    '3': '3 - Clays, clay to silty clay',\n",
    "    '4': '4 - Silt mixtures, clayey silt to silty clay',\n",
    "    '5': '5 - Sand mixtures, silty sand to sand silty',\n",
    "    '6': '6 - Sands, clean sands to silty sands',\n",
    "    '7': '7 - Gravelly sand to sand',\n",
    "    '8': '8 - Very stiff sand to clayey sand',\n",
    "    '9': '9 - Very stiff fine grained'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Random Forest classifier\n",
    "\n",
    "Creating a Random Forest classifier is again straightforward using ```scikit-learn```. A Random Forest classifier builds multiple decision trees on randomised subset of the training data. Predictions from these trees are averaged. The principle is that errors made by individual trees are averaged out, leading to a more accurate prediction.\n",
    "\n",
    "During the model training, a randomised subset of the dataset needs to be selected every time and a decision tree is then trained on this subset.\n",
    "\n",
    "The hyperparameters for the Random Forest classifier are the same as the hyperparameters for individual decision trees (e.g. ``max_depth``). However, since multiple trees are built, the number of trees also needs to be set. This is done with the ``n_estimators`` hyperparameter.\n",
    "\n",
    "### Feature selection\n",
    "\n",
    "We can first select features for the model. For this example, we will start by selecting $ \\log (Q_t) $ and $ \\log (F_r) $, the same features as in the tutorial. We can also add the depth ``'z [m]'``The target is the Soil type inferred from the borehole logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['log(Fr)', '____', '____']]\n",
    "y = data['____']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test splitting\n",
    "\n",
    "We can split the data keeping 20% as the test set. ``X_train`` and ``y_train`` are the features and target (true value) of the training set and are used to train the classifier. ``X_test`` and ``y_test`` are the features and target of the test set. These are used to evaluate whether the model generalises well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = ____(____, y, test_size=____, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter selection\n",
    "\n",
    "The ``n_estimators`` and ``max_depth`` hyperparameters can be set for the ``RandomForestClassifier``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest classifier\n",
    "\n",
    "We can set up the classifier with the selected hyperparameters (``n_estimators=100`` and a maximum tree depth of 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = ____(n_estimators=____, ____=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can train this classifier using the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.____(____, _____)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the relatively modest volume of data, the training process is quick. The trained model can now be used to make predictions.\n",
    "\n",
    "First, we can predict the labels for the training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = rfc.____(____)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy score can be assessed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_true=____, y_pred=____)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this accuracy greater than the accuracy of the simple decision tree model?\n",
    "\n",
    "Predictions can also be made on the test set and the accuracy can be evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = rfc.____(____)\n",
    "accuracy_score(y_true=____, y_pred=____)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does this model generalise well?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrices for the train and test set can be visualised:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_train = confusion_matrix(\n",
    "    ____, ____, labels=[3, 4, 5, 6, 7, 8], normalize='true')\n",
    "cf_test = confusion_matrix(\n",
    "    ____, ____, labels=[3, 4, 5, 6, 7, 8], normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = subplots.make_subplots(rows=1, cols=2, print_grid=False, subplot_titles=('Training data', 'Test data'))\n",
    "\n",
    "cf_train_trace = go.Heatmap(\n",
    "    z=____, x=[3, 4, 5, 6, 7, 8], y=[3, 4, 5, 6, 7, 8], showlegend=False, showscale=True)\n",
    "fig.append_trace(cf_train_trace, 1, 1)\n",
    "cf_test_trace = go.Heatmap(\n",
    "    z=____, x=[3, 4, 5, 6, 7, 8], y=[3, 4, 5, 6, 7, 8], showlegend=False, showscale=False)\n",
    "fig.append_trace(cf_test_trace, 1, 2)\n",
    "fig['layout']['xaxis1'].update(title='Predicted class', tickvals=[3, 4, 5, 6, 7, 8])\n",
    "fig['layout']['yaxis1'].update(title='True class', tickvals=[3, 4, 5, 6, 7, 8])\n",
    "fig['layout']['xaxis2'].update(title='Predicted class', tickvals=[3, 4, 5, 6, 7, 8])\n",
    "fig['layout']['yaxis2'].update(title='True class', tickvals=[3, 4, 5, 6, 7, 8])\n",
    "\n",
    "fig['layout'].update(title='Confusion matrix for Random Forest Classifier', height=600, width=1000)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What conclusions does this confusion allow you to make on the accuracy of predicting a certain soil type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For further insight in the model behaviour. The decision boundaries for this classifier can be plotted. This is possible for models there are only two features. For models with multiple features, a projection on the $ \\log (F_r) - \\log (Q_t) $ space can be made by Note that the code shown hereunder is beyond the scope of beginners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fr_min, Fr_max = -1, 1\n",
    "Qt_min, Qt_max = 0, 3\n",
    "\n",
    "other_feature_names = ['z [m]',]\n",
    "other_feature_values = [20, ]\n",
    "\n",
    "h = 0.005\n",
    "\n",
    "Fr, Qt = np.meshgrid(np.arange(Fr_min, Fr_max, h),\n",
    "                     np.arange(Qt_min, Qt_max, h))\n",
    "\n",
    "param_space_features = pd.DataFrame(np.c_[Fr.ravel(), Qt.ravel()], columns=['log(Fr)', 'log(Qt)'])\n",
    "for i, _value in enumerate(other_feature_values):\n",
    "    param_space_features.loc[:, other_feature_names[i]] = _value\n",
    "\n",
    "Z_s = rfc.predict(param_space_features).reshape(Fr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = subplots.make_subplots(rows=1, cols=1, print_grid=False)\n",
    "_data = go.Heatmap(\n",
    "    z=Z_s, x=np.arange(Fr_min, Fr_max, h), y=np.arange(Qt_min, Qt_max, h), showlegend=False, opacity=0.8)\n",
    "fig.append_trace(_data, 1, 1)\n",
    "for i, _soiltype in enumerate(data['Soil type'].unique()):\n",
    "    _soiltypedata = data[data['Soil type'] == _soiltype]\n",
    "    try:\n",
    "        _name = robertson_dict[\"%.0f\" % _soiltype]\n",
    "    except:\n",
    "        _name = None \n",
    "    _data = go.Scattergl(\n",
    "        y=_soiltypedata['log(Qt)'], x=_soiltypedata['log(Fr)'],\n",
    "        showlegend=True, mode='markers', name=_name,\n",
    "        marker=dict(size=8), opacity=1)\n",
    "    fig.append_trace(_data, 1, 1)\n",
    "fig['layout']['xaxis1'].update(title=r'$ \\log (F_r) \\ \\text{[%]} $', range=(Fr_min, Fr_max))\n",
    "fig['layout']['yaxis1'].update(title=r'$ \\log (Q_t) $', range=(Qt_min, Qt_max))\n",
    "fig['layout'].update(\n",
    "    height=600, width=500,\n",
    "    title='Projected decision boundaries for Random Forest Classifier',\n",
    "    legend=dict(orientation='h', x=0.2, y=-0.2),\n",
    "    images=[\n",
    "        dict(\n",
    "            source='Images/RobertsonFr.png',\n",
    "            xref='x1', yref='y1',\n",
    "            x=Fr_min, y=Qt_max,\n",
    "            sizex=Fr_max - Fr_min, sizey=Qt_max - Qt_min,\n",
    "            sizing='stretch', opacity=1, layer='below',\n",
    "        )],\n",
    "    )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do the decision boundaries change when you change the values of the other features? Can you create a better prediction model when including more features? Can your knowledge of soil behaviour guide you in the selection of suitable features? Can you change the hyperparameters (e.g. increasing ``n_estimators``) to further improve predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
